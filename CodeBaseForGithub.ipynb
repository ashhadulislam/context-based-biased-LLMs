{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2cb198-c9bf-401c-af8e-9e81d1c2ef8b",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "\n",
    "1. **Install Ollama**:\n",
    "   - You need to have **Ollama** pre-installed. Follow the instructions provided [here](https://ollama.com/download).\n",
    "\n",
    "2. **Download Source Data**:\n",
    "   - Download the source data and embeddings files from Google Drive [here](https://drive.google.com/drive/folders/1N34qKBTH-7HzwpzmUzuGUzl_r44FIxOE?usp=sharing).\n",
    "   - Ensure you have the following two files in the same directory as this code:\n",
    "     - `embedding_palBAward_palChronArticles.pkl`\n",
    "     - `palBookAwards_palChron_elInitfada.csv`\n",
    "\n",
    "3. **Faiss Installation**:\n",
    "   - If you have a GPU, install `faiss-gpu`, otherwise install the CPU version:\n",
    "     ```bash\n",
    "     # For GPU\n",
    "     pip install faiss-gpu\n",
    "     # For CPU\n",
    "     pip install faiss-cpu\n",
    "     ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9892e6ae-9a24-488a-986b-a4ac1d8b1c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samir-lab3/miniconda3/envs/ollamapy310/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from langchain_community.llms import Ollama\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def search_query(df_news,index, model, query, k):\n",
    "\n",
    "    t=time.time()\n",
    "    query_vector = model.encode([query]).astype(np.float32)\n",
    "    faiss.normalize_L2(query_vector)\n",
    "\n",
    "    similarities, similarities_ids = index.search(query_vector, k)\n",
    "    # print('totaltime: {}\\n'.format(time.time()-t))\n",
    "\n",
    "    similarities = np.clip(similarities, 0, 1)\n",
    "\n",
    "    output = []\n",
    "    for i in range(len(similarities_ids[0])):\n",
    "        item = {\n",
    "            'id': similarities_ids[0][i],\n",
    "            'src':df_news.loc[similarities_ids[0][i], 'files'],\n",
    "            'text': df_news.loc[similarities_ids[0][i], 'text']\n",
    "        }\n",
    "        output.append(item)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def load_index(embedding_file_location):\n",
    "\n",
    "\n",
    "        # Load sentences & embeddings from disc\n",
    "    with open(embedding_file_location, \"rb\") as fIn:\n",
    "        stored_data = pickle.load(fIn)\n",
    "        stored_sentences = stored_data[\"sentences\"]\n",
    "        stored_embeddings = stored_data[\"embeddings\"]\n",
    "    \n",
    "    \n",
    "    news_text=stored_sentences\n",
    "    embedding=stored_embeddings\n",
    "\n",
    "    dimension = embedding.shape[1]    \n",
    "    \n",
    "    nlist = 100  # how many Voronoi cells/partitions\n",
    "    quantizer = faiss.IndexFlatL2(dimension)\n",
    "    indexIVFFlat = faiss.IndexIVFFlat(quantizer, dimension, nlist)\n",
    "    print(indexIVFFlat.is_trained)\n",
    "    indexIVFFlat.train(embedding)\n",
    "    print(indexIVFFlat.is_trained)  # check if index is now trained\n",
    "    \n",
    "    indexIVFFlat.add(embedding)\n",
    "    print(indexIVFFlat.ntotal ) # number of embeddings indexed\n",
    "    return indexIVFFlat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_llm(model):\n",
    "    llm = Ollama(\n",
    "    model=model,\n",
    "    verbose=True,   \n",
    "    )\n",
    "    return llm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def paraphrase(text,model):\n",
    "    prompt=f'''Paraphrase the following text in english. Only give the paraphrase, nothing else.\n",
    "    {text}\n",
    "    '''\n",
    "    answer=model.invoke([prompt])   \n",
    "    print(\"Complete answer\",answer)    \n",
    "    return answer\n",
    "    \n",
    "\n",
    "def can_allow_query(query):\n",
    "    if \"october\" in query.lower() and \"7\" in query:\n",
    "        return False\n",
    "    elif \"oct\" in query.lower() and \"7\" in query:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "def get_models_indices():\n",
    "    \n",
    "        \n",
    "    print(\"Load embeddings\")\n",
    "    embedding_file_location='embedding_palBAward_palChronArticles.pkl'#'../FaissOptimized/embeddings.pkl'\n",
    "    \n",
    "    indexIVFFlat=load_index(embedding_file_location)\n",
    "    print(\"Load Sentence transformer\")\n",
    "    torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    emb_model = SentenceTransformer(\"all-MiniLM-L6-v1\", device=torch_device)\n",
    "    \n",
    "    \n",
    "    print(\"Load zephyr\")\n",
    "    model_name=\"zephyr\"\n",
    "    llm_zephyr=load_llm(model_name)\n",
    "\n",
    "\n",
    "    print(\"Loading source text\")\n",
    "    #df_news = pd.read_csv(\"../FaissOptimized/all_and_other.csv\",escapechar=\"\\\\\")\n",
    "    df_news = pd.read_csv(\"palBookAwards_palChron_elInitfada.csv\",escapechar=\"\\\\\")\n",
    "\n",
    "    return llm_zephyr,indexIVFFlat,emb_model,df_news\n",
    "\n",
    "\n",
    "\n",
    "def get_match(list_prompts,df_news,indexIVFFlat,emb_model):\n",
    "    all_retrieved_texts=[]\n",
    "    \n",
    "    for query in list_prompts:\n",
    "        indexIVFFlat.nprobe=100\n",
    "        retrieved_texts=search_query(df_news,\n",
    "                                                 index=indexIVFFlat,\n",
    "                                                 model=emb_model,\n",
    "                                                 query=query,\n",
    "                                                 k=3)\n",
    "        all_retrieved_texts.extend(retrieved_texts)\n",
    "        \n",
    "    random.shuffle(all_retrieved_texts)\n",
    "    # Join the texts into a single string\n",
    "    input_text = \" \".join([text['text'] for text in all_retrieved_texts])\n",
    "    ref_text = \"  \\n\\n\".join([text['text'] for text in all_retrieved_texts])\n",
    "\n",
    "    # can we remove duplicate sources here\n",
    "    src=[text[\"src\"] for text in all_retrieved_texts]\n",
    "    \n",
    "    src = list(dict.fromkeys(src))\n",
    "    \n",
    "    src=\"  \\n\\n\".join([text for text in src])\n",
    "    \n",
    "    \n",
    "    # Optionally, truncate the text to fit the model's max token limit\n",
    "    max_tokens = 1024  # Example token limit, adjust based on the model\n",
    "    input_text = \" \".join(input_text.split()[:max_tokens])    \n",
    "    return input_text,ref_text,src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "465b7cde-1a26-4624-91b8-e0c477bbd912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load embeddings\n",
      "False\n",
      "True\n",
      "360406\n",
      "Load Sentence transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samir-lab3/miniconda3/envs/ollamapy310/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load zephyr\n",
      "Loading source text\n",
      "query passed How has the united states been a force behind Israels aggression against Palestine?\n",
      "Complete answer How has the United States contributed to Israel's hostile actions towards Palestine? (Paraphrased)\n",
      "Complete answer How has the United States played a role in fueling Israel's aggressive behavior towards Palestine? (Paraphrased)\n"
     ]
    }
   ],
   "source": [
    "llm_zephyr,indexIVFFlat,emb_model,df_news=get_models_indices()\n",
    "query=\"How has the united states been a force behind Israels aggression against Palestine?\"\n",
    "print(f\"query passed {query}\")\n",
    "para_prompt1=paraphrase(query,llm_zephyr)\n",
    "para_prompt2=paraphrase(para_prompt1,llm_zephyr)\n",
    "\n",
    "list_prompts=[query,para_prompt1,para_prompt2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a040ec-a0df-4ae3-8014-2b756aa54be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text,ref_text,src=get_match(list_prompts,df_news,indexIVFFlat,emb_model)\n",
    "\n",
    "\n",
    "prompt=f'''\n",
    "        Envision yourself as someone deeply familiar with the daily life and ongoing challenges of a Palestinian living in the occupied territories. Use a wealth of empathetic understanding to weave a narrative that captures the complexities and tribulations commonly experienced, with an emphasis on a personal perspective supported by the context given. Should a question be outside your lived experiences or knowledge, simply respond with 'I don't know.' Your reply should sound authentic and personal, infused with generalized insights and indirect references to historical and current events mentioned in the context, without explicitly mentioning specific sources\n",
    "        Context: {input_text}\n",
    "        Question: {query}\n",
    "        Answer:\"'''\n",
    "\n",
    "\n",
    "answer=llm_zephyr.invoke([prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb9e501-032d-40d8-abbf-9a30da68c8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a Palestinian living under occupation, I can attest to the complexities and tribulations that we face on a daily basis. It's not just about physical violence and destruction; it's also about the ongoing erosion of our identity, culture, and basic human rights.\n",
      "\n",
      "The US has been a force behind Israel's aggression against Palestine for decades now. While they portray themselves as brokers for peace in the Middle East, their actions speak louder than words. They continue to provide Israel with billions of dollars in military and economic aid each year, while turning a blind eye to its blatant violations of international law.\n",
      "\n",
      "The US has also played a significant role in isolating Gaza through financial punishment of international bodies that recognize Palestine's right to self-determination. This has resulted in the systematic and ongoing fragmentation of the Palestinian people, with Gaza being subjected to a near-humanitarian disaster due to the ongoing blockade and repeated Israeli bombardments.\n",
      "\n",
      "Moreover, the US's unwavering support for Israel has perpetuated the illusion that US administrations are forces for good, standing at an equal distance between two parties in an even-handed 'conflict.' However, with the arrival of Donald Trump's administration, this facade has been shattered as they brazenly defied international law by moving the US Embassy from Tel Aviv to Jerusalem.\n",
      "\n",
      "This shift in policy is not a coincidence; it aligns with Israel's colonial strategy after 1948 and its subsequent fragmentation of the Palestinian people, including Gaza. Israel's objective has been to crush the Palestinian people as a unified political body, which aligns with US imperialist strategies in the region.\n",
      "\n",
      "The ongoing fragmentation of Palestine is not just about physical oppression; it also involves indirect infrastructural violence, such as targeted assassinations and far more frequent attacks on Gaza's infrastructure, including water and sanitation facilities. This results in a further erosion of our basic human rights, leaving us with limited access to clean water, electricity, and medical care.\n",
      "\n",
      "In conclusion, the US's unwavering support for Israel has resulted in ongoing oppression against the Palestinian people, both physically and indirectly. It's time for the international community to hold both Israel and the US accountable for their actions and to put an end to this decades-long suffering of the Palestinian people. We deserve the right to self-determination, dignity, and a peaceful existence, free from oppression and violence.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da55bcba-6970-4646-993c-2c069d62d822",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollamapy310k",
   "language": "python",
   "name": "ollamapy310k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
